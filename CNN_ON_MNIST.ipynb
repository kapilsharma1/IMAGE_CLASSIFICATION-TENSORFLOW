{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN ON MNIST",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JI5J_vCPDX7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#This project uses a CNN model to clssify MNIST digits with a 99%.2 Accuracy."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJKQODpmdQE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#importing the essential libraries.\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VQX-NnZrdWun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "e304a935-33bc-4ad8-a491-ad2109226db6"
      },
      "cell_type": "code",
      "source": [
        "#Importing the data\n",
        "mnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
        "tr_x,tr_y,te_x,te_y=mnist.train.images,mnist.train.labels,mnist.test.images,mnist.test.labels"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-8dc6b31d3540>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wRBz1PdkeAJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tr_x=tr_x.reshape([-1,28,28,1])\n",
        "te_x=te_x.reshape([-1,28,28,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v3hlZnVBiwnq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Defining helper functions\n",
        "def init_weights(shape):\n",
        "  return(tf.Variable(tf.random_normal(shape,stddev=0.01)))\n",
        "\n",
        "def init_bias(shape):\n",
        "  return(tf.Variable(tf.constant(0.1,shape=shape)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mfw5CjbMjNkm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv2d(X,w):\n",
        "  return tf.nn.conv2d(X,w,strides=[1,1,1,1],padding=\"SAME\")\n",
        "\n",
        "def max_pool_2by2(X):\n",
        "  return tf.nn.max_pool(X,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OU9DpDNGkAoN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv_layer(X,shape):\n",
        "  w=init_weights(shape)\n",
        "  b=init_bias([shape[3]])\n",
        "  return(tf.nn.relu(conv2d(X,w))+b)\n",
        "\n",
        "def normal_full_layer(input_x,output_units):\n",
        "  input_units=int(input_x.get_shape()[1])\n",
        "  w=init_weights([input_units,output_units])\n",
        "  b=init_bias([output_units])\n",
        "  return tf.matmul(input_x,w)+b\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ADKEJLPfluU3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Defining placeholders\n",
        "x=tf.placeholder(tf.float32,shape=[None,28,28,1])\n",
        "y=tf.placeholder(tf.float32,shape=[None,10])\n",
        "keep_conv=tf.placeholder(tf.float32)\n",
        "keep_hidden=tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JtlDjpc6p3Gm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPNn4Cr3qCWo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Defining the model graph\n",
        "conv1=conv_layer(x,[3,3,1,32])\n",
        "conv1=max_pool_2by2(conv1)\n",
        "conv1=tf.nn.dropout(conv1,keep_conv)\n",
        "conv2=conv_layer(conv1,[3,3,32,64])\n",
        "conv2=max_pool_2by2(conv2)\n",
        "conv2=tf.nn.dropout(conv2,keep_conv)\n",
        "conv3=conv_layer(conv2,[3,3,64,128])\n",
        "conv3=max_pool_2by2(conv3)\n",
        "conv3=tf.nn.dropout(conv3,keep_conv)\n",
        "conv3_flat=tf.reshape(conv3,[-1,128*4*4])\n",
        "dense1=tf.nn.relu(normal_full_layer(conv3_flat,625))\n",
        "dense1=tf.nn.dropout(dense1,keep_hidden)\n",
        "dense2=normal_full_layer(dense1,10)\n",
        "\n",
        "y_pred=tf.argmax(dense2,axis=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "64_xZRe0u47M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "7edb212a-bc9d-484c-c570-22f698c1ee99"
      },
      "cell_type": "code",
      "source": [
        "#Defining the training loss and optimizer\n",
        "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=dense2))\n",
        "optimizer=tf.train.RMSPropOptimizer(0.001,0.9)\n",
        "train=optimizer.minimize(loss)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-60f2cb1d4eb4>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Szr-9WUqymJg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#defining the varibales and hyperparameters\n",
        "num_epochs=100\n",
        "batch_size=128\n",
        "test_size=256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nal8OPXczNMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1697
        },
        "outputId": "3d88b4d3-25fe-406c-df61-f477a93de27e"
      },
      "cell_type": "code",
      "source": [
        "#This is the main cell for training the model.\n",
        "with tf.Session() as sess:\n",
        "    # you need to initialize all variables\n",
        "    tf.global_variables_initializer().run()\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "        training_batch = zip(range(0, len(tr_x), batch_size),\n",
        "                             range(batch_size, len(tr_x)+1, batch_size))\n",
        "        for start, end in training_batch:\n",
        "            sess.run(train, feed_dict={x: tr_x[start:end], y: tr_y[start:end],\n",
        "                                          keep_conv: 0.5, keep_hidden: 0.5})\n",
        "\n",
        "        test_indices = np.arange(len(te_x)) # Get A Test Batch\n",
        "        np.random.shuffle(test_indices)\n",
        "        test_indices = test_indices[0:test_size]\n",
        "#printing the accuracy after each epoch\n",
        "        print(i, np.mean(np.argmax(te_y[test_indices], axis=1) ==\n",
        "                         sess.run(y_pred, feed_dict={x: te_x[test_indices],\n",
        "                                                        keep_conv: 1.0,\n",
        "                                                         keep_hidden: 1.0})))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.08984375\n",
            "1 0.91796875\n",
            "2 0.96484375\n",
            "3 0.98828125\n",
            "4 0.984375\n",
            "5 0.98828125\n",
            "6 0.98046875\n",
            "7 0.9921875\n",
            "8 0.98046875\n",
            "9 0.99609375\n",
            "10 0.9921875\n",
            "11 0.984375\n",
            "12 0.984375\n",
            "13 0.984375\n",
            "14 0.99609375\n",
            "15 0.98046875\n",
            "16 1.0\n",
            "17 0.99609375\n",
            "18 0.9921875\n",
            "19 0.99609375\n",
            "20 0.984375\n",
            "21 0.984375\n",
            "22 0.9921875\n",
            "23 1.0\n",
            "24 0.99609375\n",
            "25 0.98828125\n",
            "26 0.98828125\n",
            "27 0.9921875\n",
            "28 1.0\n",
            "29 0.9921875\n",
            "30 0.9921875\n",
            "31 0.99609375\n",
            "32 1.0\n",
            "33 0.9921875\n",
            "34 0.984375\n",
            "35 0.9921875\n",
            "36 0.984375\n",
            "37 0.99609375\n",
            "38 0.99609375\n",
            "39 0.9921875\n",
            "40 0.98828125\n",
            "41 0.98046875\n",
            "42 0.9921875\n",
            "43 0.98828125\n",
            "44 0.99609375\n",
            "45 0.984375\n",
            "46 0.984375\n",
            "47 0.98828125\n",
            "48 0.9921875\n",
            "49 0.9921875\n",
            "50 1.0\n",
            "51 0.99609375\n",
            "52 0.99609375\n",
            "53 0.99609375\n",
            "54 0.9921875\n",
            "55 0.98046875\n",
            "56 0.99609375\n",
            "57 0.984375\n",
            "58 0.9921875\n",
            "59 0.9921875\n",
            "60 0.9921875\n",
            "61 0.9921875\n",
            "62 0.9921875\n",
            "63 0.99609375\n",
            "64 1.0\n",
            "65 0.98828125\n",
            "66 1.0\n",
            "67 0.99609375\n",
            "68 0.98828125\n",
            "69 0.9921875\n",
            "70 0.98828125\n",
            "71 1.0\n",
            "72 0.99609375\n",
            "73 0.98828125\n",
            "74 0.98046875\n",
            "75 0.99609375\n",
            "76 0.9921875\n",
            "77 0.99609375\n",
            "78 0.99609375\n",
            "79 0.9921875\n",
            "80 0.9921875\n",
            "81 0.984375\n",
            "82 0.9921875\n",
            "83 0.9921875\n",
            "84 0.984375\n",
            "85 1.0\n",
            "86 0.9921875\n",
            "87 0.9921875\n",
            "88 0.9921875\n",
            "89 0.98046875\n",
            "90 0.9921875\n",
            "91 0.98828125\n",
            "92 0.98828125\n",
            "93 0.984375\n",
            "94 0.99609375\n",
            "95 0.98046875\n",
            "96 0.99609375\n",
            "97 0.9921875\n",
            "98 0.99609375\n",
            "99 0.9921875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oA2y30_WOqW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Final Accuracy after 100 epochs is 99.2%"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}